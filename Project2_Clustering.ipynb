{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage      \n",
    "import sklearn.feature_extraction.text as sk_text\n",
    "import sklearn.cluster as sk_cluster\n",
    "import sklearn.metrics as metrics\n",
    "%matplotlib inline\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import matplotlib.pyplot as plt\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "import datetime\n",
    "startTime = datetime.datetime.now()\n",
    "print(str(startTime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#print initial data\n",
    "\n",
    "tweets = pd.read_csv('clean_data.csv',dtype=str)\n",
    "tweets['FrequencyOver20'] = tweets.FrequencyOver20.str.lower()\n",
    "tweets.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregateTweetsHashtags = tweets.groupby('UserID')['FrequencyOver20'].apply(lambda x: x.str.cat(sep=' '))\n",
    "tweetsPrepareSKText = pd.DataFrame({'User_id': aggregateTweetsHashtags.index, 'All_hashtags': aggregateTweetsHashtags.values})\n",
    "vectorizer = sk_text.TfidfVectorizer(max_features = 4,\n",
    "                             #min_df=100, \n",
    "                             max_df=.8,\n",
    "                             stop_words = 'english'\n",
    "                             )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "matrix = vectorizer.fit_transform(tweetsPrepareSKText.All_hashtags.values)\n",
    "tdidf = matrix.toarray()\n",
    "df_text = pd.DataFrame(matrix.todense(), index=aggregateTweetsHashtags.index, columns=vectorizer.get_feature_names())\n",
    "df_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_cols = ['UserID', 'GROUND_TRUTH_TEAM']\n",
    "ground_truth = pd.read_table('clinton_trump_user_classes.txt', encoding =\"ISO-8859-1\", dtype=str, names= ground_cols)\n",
    "#ground_truth.UserID = ground_truth.UserID.astype(int)\n",
    "df_text = pd.merge(df_text, ground_truth, on = 'UserID')\n",
    "#ground truth\n",
    "true = df_text['GROUND_TRUTH_TEAM'].astype(int).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cluster centers is acs_order_centroids\n",
    "def printClusters(vectorizer,cluster_centers,num_cluster,num_to_print):\n",
    "    cluster_centers_reversed = cluster_centers[:,::-1]\n",
    "    des_order_centroids = cluster_centers.argsort()[:,::-1]     #  get the indices that sort array in descending order\n",
    "    terms = vectorizer.get_feature_names()\n",
    "\n",
    "    for i in range(num_cluster):\n",
    "        print (\"Cluster:\", i)\n",
    "        for indx,ind in enumerate(des_order_centroids[i, : num_to_print]):\n",
    "            print (terms[ind],cluster_centers_reversed[i,indx],ind )\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printMetrics(true,kmeans):\n",
    "    print('confusion matrix\\n',metrics.confusion_matrix(true, kmeans.labels_, labels=[0, 1]))\n",
    "    print('Precision',metrics.precision_score(true, kmeans.labels_, average='weighted')) # weighted: the average precision of all clusters is returned\n",
    "    print('Recall',metrics.recall_score(true, kmeans.labels_, average='weighted'))  # weighted: the average recall of all clusters is returned\n",
    "    print('F1 Score',metrics.f1_score(true, kmeans.labels_, average= 'weighted'))     # weighted: the average f1 of all clusters is returned\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**K-means Clustering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "kmeans = sk_cluster.KMeans(n_clusters=2, n_init=20, max_iter=200)  \n",
    "km_labels = kmeans.fit_predict(tdidf)\n",
    "error = kmeans.inertia_       #SSE; Sum of squared distances of tsamples to their closest cluster center."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"\\nThe total error of the clustering is: \", error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printMetrics(true,kmeans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printClusters(vectorizer, kmeans.cluster_centers_,2,30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans.cluster_centers_[:,::-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans.cluster_centers_.argsort()[:,::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MAX-Agglomerative Clustering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## parameter “linkage” to “complete” gives you MAX-based agglomerative hierarchical clustering\n",
    "\n",
    "ag = sk_cluster.AgglomerativeClustering(linkage = 'complete', n_clusters = 2)   \n",
    "ag_labels = ag.fit_predict(tdidf)\n",
    "\n",
    "printMetrics(true,ag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SSE-Agglomerative Clustering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## parameter “linkage” to “ward” gives you SSE-based agglomerative hierarchical clustering\n",
    "\n",
    "ag = sk_cluster.AgglomerativeClustering(linkage = 'ward', n_clusters = 2)   \n",
    "ag_labels = ag.fit_predict(tdidf)\n",
    "\n",
    "printMetrics(true,ag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1.3 (10 pts): Show the two respective word clouds of the two centers (centroids) by using hashtags/handles and their tfidf values. Hint: Use function fit_words() that comes with wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create stopword list:\n",
    "stopwords = set(STOPWORDS)\n",
    "\n",
    "# Generate a word cloud image\n",
    "wordcloud = WordCloud(stopwords=stopwords).fit_words(vectorizer.vocabulary_)\n",
    "\n",
    "# Display the generated image:\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ag = sk_cluster.AgglomerativeClustering(linkage = 'ward', n_clusters = 3)   \n",
    "\n",
    "#complete: The maximum distances\n",
    "#n_clusters: The number of clusters to find.\n",
    "\n",
    "ag_labels = ag.fit_predict(tdidf)\n",
    "\n",
    "print ('\\nPrinting cluster assignment:')\n",
    "ag_labels "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1: First, you apply the k-means algorithm. Create a plot of the SSE error of the k-means algorithm as a function of the number of clusters, for k up to 20, in order to determine the optimal number of clusters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "error = np.zeros(30)\n",
    "for k in range(20,30):\n",
    "    kmeans = sk_cluster.KMeans(n_clusters=k, n_init=10, max_iter=300)\n",
    "    kmeans.fit_predict(tdidf)\n",
    "    error[k] = kmeans.inertia_\n",
    "\n",
    "plt.plot(range(20, 30), error[20:])\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('SSE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2: Run the k-means algorithm for the optimal number of clusters you identified in the last task. Print some hashtags/handles in each cluster. From the hashtags/handles in each cluster, try to deduce what is the topic it concerns. Include your conclusions in your report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = sk_cluster.KMeans(n_clusters=20, n_init=10, max_iter=300)\n",
    "kmeans.fit_predict(tdidf)\n",
    "printClusters(vectorizer, kmeans.cluster_centers_, 20,30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
