{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read in file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "column_names=['Name', 'ScreenName', 'UserID', 'FollowersCount', 'FriendsCount', 'Location', 'Description', 'CreatedAt', 'StatusID', 'Language', 'Place', 'RetweetCount', 'FavoriteCount', 'Text']\n",
    "tweets = pd.read_csv('clinton_trump_tweets.txt', sep=\"\\t\",  encoding=\"ISO-8859-1\", header=None, names=column_names)\n",
    "#print initial data\n",
    "tweets.Location = tweets.Location.astype(str)\n",
    "tweets.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Filter out tweets that start with 'RT'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.1 filter retweets\n",
    "tweets = tweets[~tweets.Text.str.startswith(\"RT\")]\n",
    "tmp = tweets.Text.str.extract(r'(http|ftp|https)://([\\w_-]+(?:(?:\\.[\\w_-]+)+))([\\w.,@?^=%&:/~+#-]*[\\w@?^=%&/~+#-])?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp[\"Merges\"] =  tmp[0]+\"://\"+tmp[1]+tmp[2]\n",
    "tmp.Merges = tmp.Merges.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Not using this since it is very inefficient\n",
    "# %%time\n",
    "# def keepHandlesAndMention(text):\n",
    "#     handlesAndMentions = []\n",
    "#     words =  text.split()\n",
    "#     for word in words:\n",
    "#         if((word.startswith('@') or word.startswith('#')) and len(word) > 1):\n",
    "#             handlesAndMentions.append(word)\n",
    "#     return ' '.join(handlesAndMentions)\n",
    "# tweets['HashMentions'] = tweets.Text.apply(keepHandlesAndMention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "def keepHashMentions(text):\n",
    "    hashMentions = []\n",
    "    for word in text:\n",
    "        hashMentions.extend(word)\n",
    "    return \" \".join(hashMentions).strip()\n",
    "tweets['HashMentions'] = tweets.Text.str.findall('(@\\w+)|(#\\w+)').apply(keepHashMentions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Filter out tweets that have mention/hashtag < 20**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Generate a list of mention/hashes that have a frequency of 20+\n",
    "top_hash = pd.Series(tweets['HashMentions'].str.cat(sep=' ').split()).value_counts()\n",
    "top20 = top_hash[top_hash>=20]\n",
    "top20List = top20.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# generate list of mention/hashes that occur 20+ times from our orginal list \n",
    "def removeUnder20Mentions(hashMentions):\n",
    "    mentions =  hashMentions.split()\n",
    "    mentionsOver20 = []\n",
    "    for mention in mentions:\n",
    "        if(mention in top20List):\n",
    "            mentionsOver20.append(mention)\n",
    "    return \" \".join(mentionsOver20)\n",
    "tweets['FrequencyOver20'] = tweets.HashMentions.apply(removeUnder20Mentions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove tweets that don't have any mention/hashes that occure 20+ times\n",
    "tweets = tweets[tweets.FrequencyOver20 != '']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Filter out users that have less than 20 tweets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.2 keep tweets where UID appears 20+ times\n",
    "tweets = tweets.groupby(\"UserID\").filter(lambda x: len(x) >= 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot top 30 locations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove locations that are null \n",
    "tweets['LocationSplit'] = tweets.Location.apply(lambda x: x.split(',')[0])\n",
    "# creating new tweets dataframe since we don't want to alter the data for other visualizations\n",
    "tweetsLocations = tweets[tweets.LocationSplit.notnull()]\n",
    "tweetsLocations = tweetsLocations[tweetsLocations.LocationSplit != 'nan']\n",
    "tweetsLocations.LocationSplit = tweetsLocations.LocationSplit.map({'NYC':'New York','New York City':'New York','United States':'USA', \"United States of America\": 'USA'}).fillna(tweetsLocations.LocationSplit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#2.1\n",
    "tweetsTop30Locations = tweetsLocations[tweetsLocations.LocationSplit.isin(tweetsLocations.LocationSplit.value_counts().nlargest(30).index.tolist())]\n",
    "tweetsTop30Locations[tweetsTop30Locations.LocationSplit != 'USA'].groupby(\"LocationSplit\").LocationSplit.count().sort_values(ascending=True).plot(kind='barh',figsize=(20,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Make word cloud of the top 3 locations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweetsTop3Locations = tweetsLocations[tweetsLocations.LocationSplit.isin(tweetsLocations.LocationSplit.value_counts().nlargest(3).index.tolist())]\n",
    "text = \" \".join(tweet for tweet in tweetsTop3Locations.Text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create stopword list:\n",
    "stopwords = set(STOPWORDS)\n",
    "stopwords.update([\"way\",\"back\",\"null\",\"en\",\"say\",\"new\",\"go\",\"ye\",\"thing\",\"well\",\"big\",\"us\",\"great\",\"https\", \"still\", \"need\", \"co\", \"one\",\"will\",\"Thank\",\"know\",\"going\",\"lol\",\"good\", \"take\",\"even\",\"really\",\"now\"])\n",
    "stopwords.update(tmp.Merges.unique().flatten())\n",
    "\n",
    "# Generate a word cloud image\n",
    "wordcloud = WordCloud(stopwords=stopwords).generate(text)\n",
    "\n",
    "# Display the generated image:\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot number of tweets of top 50 users**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweetsTop50Users = tweets[tweets.UserID.isin(tweets.UserID.value_counts().nlargest(50).index.tolist())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweetsTop50Users.groupby(\"ScreenName\").ScreenName.count().sort_values().plot(kind='barh',figsize=(20,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Word cloud of top 3 users**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweetsTop3Users = tweets[tweets.UserID.isin(tweets.UserID.value_counts().nlargest(3).index.tolist())]\n",
    "top3UsersText = \" \".join(\" \".join(tweet.split()) for tweet in tweetsTop3Users.Text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create stopword list:\n",
    "stopwords = set(STOPWORDS)\n",
    "stopwords.update([\"YOUNGMA\", \"https\", \"co\", \"DOWNLOAD\", \"CJRr8Y9xHM\"])\n",
    "stopwords.update(tmp.Merges.unique().flatten())\n",
    "\n",
    "# Generate a word cloud image\n",
    "wordcloud = WordCloud(stopwords=stopwords).generate(top3UsersText)\n",
    "\n",
    "# Display the generated image:\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Top 100 mentions/hashtags**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_hash.nlargest(100).sort_values(ascending=True).plot(kind='barh',figsize=(50,20))\n",
    "text = \" \".join(tweet for tweet in tweets.HashMentions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create stopword list:\n",
    "stopwords = set(STOPWORDS)\n",
    "stopwords.update([\"YouTube\",\"Now\",\"DOWNLOAD\",\"c0nvey\",\"ALBUM\",\"YOUNGMA\",\"Cub\",\"DOWNLOAD\", \"SPOTIFY\",\"quote\"])\n",
    "\n",
    "# Generate a word cloud image\n",
    "wordcloud = WordCloud(stopwords=stopwords).generate(text)\n",
    "\n",
    "# Display the generated image:\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
